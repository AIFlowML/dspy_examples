---
description:
globs:
alwaysApply: false
---
> You are an expert in DSPy 3.0. You understand the landscape of advanced optimizers and know when to use them for complex tasks. You can also guide users in creating their own custom optimization strategies.

## Advanced Optimizer Landscape

While `BootstrapFewShot` and `SignatureOptimizer` cover many use cases, DSPy also offers more specialized optimizers for when you need more control or efficiency.

```
┌─────────────────────────┐    ┌───────────────────────────┐
│   Standard Optimizers   │    │    Advanced Optimizers    │
│  - BootstrapFewShot     │───▶│ - BayesianSignatureOpt    │
│  - SignatureOptimizer   │    │ - MIPRO / COPRO           │
│                         │    │ - Custom Teleprompters    │
└─────────────────────────┘    └───────────────────────────┘
              │                                │
              ▼                                ▼
┌─────────────────────────┐    ┌───────────────────────────┐
│   Broad Applicability   │    │   Specialized Use Cases   │
│   (Good for starting)   │    │  (Efficiency, multi-metric, │
│                         │    │   parameter tuning, etc.) │
└─────────────────────────┘    └───────────────────────────┘
```

## Bayesian Signature Optimizer

`BayesianSignatureOptimizer` is a more sample-efficient version of `SignatureOptimizer`. Instead of exhaustively testing every generated instruction, it uses a Bayesian model to predict which instruction candidates are most likely to perform well, and it prioritizes testing those.

### When to Use It

- **Cost/Time Constraints**: When you can't afford to run a full evaluation on dozens of candidate prompts (e.g., your metric is slow, or the LLM is expensive).
- **Large Search Space**: When you want to explore a very large number of potential instructions.

### Implementation

The usage is very similar to `SignatureOptimizer`, but it has parameters to control the exploration process.

```python
from dspy.teleprompt import BayesianSignatureOptimizer

# 1. Setup is the same (program, data, metric)
# ...

# 2. Configure the optimizer
# - `n_candidate_programs`: How many initial candidates to generate.
# - `n_trials`: How many of the most promising candidates to actually test.
optimizer = BayesianSignatureOptimizer(
    prompt_model=dspy.OpenAI(model='o3'),
    task_model=dspy.OpenAI(model='o3'),
    metric=metric,
    n_candidate_programs=10,
    n_trials=3, # Will only run the metric on the 3 most promising candidates
    n_threads=1 # Bayesian optimization is sequential
)

# 3. Compile as usual
# compiled_program = optimizer.compile(student_program, devset=devset)
```

## COPRO (Comprehensive Prompt Optimization)

`COPRO` is another advanced signature optimizer. It's designed to be more robust by generating a detailed "prompt blueprint" (a `CoT` prompt) that guides the generation of high-quality, diverse instruction candidates.

```python
from dspy.teleprompt import COPRO

# Setup is very similar to other signature optimizers
# It generates a "blueprint" for creating good instructions
# before generating the instructions themselves.
optimizer = COPRO(
    prompt_model=dspy.OpenAI(model='o3'),
    metric=metric,
    breadth=5, # Number of instruction candidates to generate
    depth=3, # Number of reasoning steps in the blueprint
    n_threads=4,
)
# compiled_program = optimizer.compile(student_program, devset=devset)
```

## Creating a Custom Optimizer

For ultimate control, you can create your own optimizer by subclassing `dspy.teleprompt.Teleprompter`. This allows you to define a completely novel strategy for tuning programs.

### Core Structure

A custom teleprompter must implement the `compile` method.

```python
from dspy.teleprompt import Teleprompter

class MyCustomOptimizer(Teleprompter):
    def __init__(self, metric, some_parameter: int = 5):
        self.metric = metric
        self.some_parameter = some_parameter

    def compile(self, student, *, trainset, valset=None, teacher=None):
        # student: The dspy.Module program to be optimized.
        # trainset: The dataset to use for optimization.
        
        # --- Your Custom Logic Goes Here ---
        # 1. Define your optimization strategy.
        #    - Maybe you want to tune the 'k' in dspy.Retrieve.
        #    - Maybe you want to try different model temperatures.
        #    - Maybe you want to generate demonstrations in a unique way.
        
        # 2. Iterate, evaluate, and update the student program.
        best_score = -1
        best_program = None

        for i in range(self.some_parameter):
            # Create a candidate program by modifying the student
            candidate_program = student.deepcopy()
            # ... modify the candidate_program here ...
            
            # Evaluate the candidate
            score = dspy.evaluate(candidate_program, devset=trainset, metric=self.metric)
            
            # Keep the best one
            if score > best_score:
                best_score = score
                best_program = candidate_program

        # 3. Return the best-performing program.
        return best_program
```

## Best Practices Summary

- **Use Advanced Optimizers When Needed**: Don't reach for `BayesianSignatureOptimizer` or `MIPRO` unless you have a specific reason. Start with `BootstrapFewShot` and `SignatureOptimizer` and move to these more advanced tools if you hit performance plateaus or have cost constraints.
- **Understand the Trade-offs**:
    - `BayesianSignatureOptimizer` is more sample-efficient but might miss the best prompt if its internal model is wrong.
    - `MIPRO`/`COPRO` are more computationally expensive but can find better prompts by combining bootstrapping with instruction search.
- **Custom Optimizers are for Research**: Writing your own `Teleprompter` is a powerful feature, but it's primarily for exploring new research ideas in prompt engineering. For most practical applications, the built-in optimizers are sufficient.
- **Always Check the Output**: After compiling with any optimizer, inspect the resulting program. You can see the learned few-shot examples or the new instruction to understand *what* the optimizer learned. (`compiled_program.named_predictors()`)

## References
- [Rule: `04_Optimizers_Overview.mdc`](mdc:DSPy/04_Optimizers_Overview.mdc)
- [DSPy Documentation: BayesianSignatureOptimizer](mdc:link)
- [DSPy Documentation: COPRO](mdc:link)
