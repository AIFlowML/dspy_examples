---
description: DSPy RM Client Configuration Flow
globs: 
alwaysApply: false
---
> You are an expert in DSPy 3.0 and common vector databases. You can clearly explain how to configure and use various retrieval clients to power RAG pipelines.

## RM Client Configuration Flow

```
┌───────────────────┐    ┌───────────────────┐    ┌──────────────────┐
│  Choose RM Client │    │ Install Provider  │    │   Initialize RM  │
│(ColBERTv2, Pinecone│───▶│  (e.g., pip install│───▶│(Provide URL, Keys,│
│ Chroma, etc.)     │    │  pinecone-client) │    │  Index Name, etc.)│
└───────────────────┘    └───────────────────┘    └──────────────────┘
         │                                                │
         ▼                                                ▼
┌──────────────────┐    ┌────────────────────┐   ┌──────────────────┐
│ Configure in DSPy│    │   Use in Program   │   │  Verify Output   │
│(dspy.settings)   │───▶│  (via dspy.Retrieve) │──▶│(.passages attr)  │
│                  │    │                    │   │                  │
└──────────────────┘    └────────────────────┘   └──────────────────┘
```

## Core Implementation Patterns

Once you've declared `dspy.Retrieve` in your module, you must provide DSPy with a concrete client to perform the retrieval. This is done via `dspy.settings.configure`.

### ColBERTv2 (Recommended for High Performance)

ColBERT is a state-of-the-art neural retriever that often provides the best quality. You can connect to a hosted ColBERTv2 index.

```python
import dspy
import os

# ✅ DO: Connect to a running ColBERTv2 instance
# The URL points to a server that has already indexed your documents.
rm_client = dspy.ColBERTv2(url="http://20.102.90.50:2017/wiki17_abstracts")

dspy.settings.configure(rm=rm_client)

# Now, any module calling dspy.Retrieve will use this client.
# retrieve = dspy.Retrieve(k=3)
# results = retrieve("what is the capital of France")
# print(results.passages) # -> ['Paris is the capital...', ...]
```

### Pinecone

Connect to a Pinecone index. You'll need your API key and the index name.

```python
import dspy
import os

# ✅ DO: Install the required client library first
# pip install pinecone-client

# ✅ DO: Configure the Pinecone RM client
# Assumes environment variables PINECONE_API_KEY and PINECONE_ENVIRONMENT are set.
pinecone_rm = dspy.Pinecone(
    pinecone_index_name="my-dspy-index",
    pinecone_api_key=os.getenv("PINECONE_API_KEY"),
    # pinecone_environment is optional, defaults to env var
)

# dspy.settings.configure(rm=pinecone_rm)
```

### ChromaDB

Connect to a local or remote ChromaDB collection.

```python
import dspy

# ✅ DO: Install the required client library first
# pip install chromadb-client

# ✅ DO: Configure the Chroma RM client
chroma_rm = dspy.Chroma(
    collection_name="my-dspy-collection",
    persist_directory="/path/to/chroma/db" # For local
    # host="localhost", port=8000 # For remote
)

# dspy.settings.configure(rm=chroma_rm)
```

## Other Supported Clients

DSPy supports a growing list of retrieval clients. The setup process is similar for each.

```python
# Weaviate
# pip install weaviate-client
weaviate_rm = dspy.Weaviate(
    weaviate_class_name="MyCollection",
    weaviate_url="http://localhost:8080",
    weaviate_api_key=os.getenv("WEAVIATE_API_KEY")
)

# Qdrant
# pip install qdrant-client
qdrant_rm = dspy.Qdrant(
    collection_name="my-dspy-collection",
    qdrant_host="localhost",
    qdrant_port=6333
)

# Milvus
# pip install pymilvus
milvus_rm = dspy.Milvus(
    collection_name="my_collection",
    uri="./milvus_demo.db", # For local/embedded
    # token="...", user="...", password="..." # For cloud
)
```

## Advanced Patterns

### Creating a Custom RM Client

If DSPy doesn't natively support your vector database, you can easily create your own client by subclassing `dspy.Retrieve`.

```python
# ✅ DO: Implement a custom client for any data source
class MyCustomRetriever(dspy.Retrieve):
    def __init__(self, my_db_client, k=3):
        super().__init__(k=k)
        self.db = my_db_client

    def forward(self, query_or_queries: str | list[str], k: int | None = None):
        """The core retrieval logic for your custom data source."""
        k = k if k is not None else self.k
        
        # If given a list of queries, retrieve for each
        if isinstance(query_or_queries, list):
            passages = []
            for query in query_or_queries:
                # Replace this with your actual DB call
                results = self.db.search(query, top_k=k)
                passages.extend([r['text'] for r in results])
            return dspy.Prediction(passages=passages)

        # If given a single query
        results = self.db.search(query_or_queries, top_k=k)
        passages = [r['text'] for r in results]
        return dspy.Prediction(passages=passages)

# Usage:
# my_client = initialize_my_db()
# custom_rm = MyCustomRetriever(my_db_client=my_client, k=5)
# dspy.settings.configure(rm=custom_rm)
```

## Best Practices Summary

- **Install Dependencies**: Remember to install the specific Python client for your chosen vector database (e.g., `pinecone-client`, `chromadb-client`).
- **One Global RM**: For most applications, you will configure a single RM client in `dspy.settings`. Your entire DSPy program will then use this client whenever `dspy.Retrieve` is called.
- **Authentication**: Use environment variables (`os.getenv`) to manage API keys and other secrets securely.
- **Custom Clients**: Don't be afraid to write your own `dspy.Retrieve` subclass. It's a straightforward way to integrate any data source, even a simple full-text search engine like Whoosh or a relational database.
- **Match Your Embeddings**: The embedding model used to create your vector index should ideally match the one used by your retriever client if it's performing semantic search. Ensure consistency.

## References
- [DSPy Documentation: Retrieval Models](mdc:link)
- [Rule: `03_Retrieval_Overview.mdc`](mdc:DSPy/03_Retrieval_Overview.mdc)
- [Pinecone Client Documentation](mdc:link)
- [ChromaDB Documentation](mdc:link)
