---
description: DSPy Tracking Optimizer Runs with MLflow
globs: 
alwaysApply: false
---
> You are an expert in DSPy 3.0 and MLOps. You are creating a practical example of how to track DSPy program optimization using MLflow for better traceability and debugging.

## DSPy Example: Tracking Optimizer Runs with MLflow

This example demonstrates how to integrate MLflow to track, analyze, and debug the DSPy optimization process (`teleprompter.compile`). MLflow's native DSPy integration provides deep traceability into optimization, allowing you to inspect intermediate trials, store optimized programs, and observe program execution traces.

### MLflow Autologging Captures:

-   **Optimizer Parameters**: Configuration settings like the number of few-shot examples and candidates.
-   **Program States**: Snapshots of instructions and few-shot examples at initial, intermediate, and final optimization stages.
-   **Datasets**: The training and evaluation data used.
-   **Performance Progression**: A timeline of evaluation metrics.
-   **Execution Traces**: Detailed traces of program execution, including model responses and intermediate prompts.

---

## 1. Project Setup

### Environment and Dependencies

Set up your Python environment and install the required packages using `uv`.

```bash
# 1. Create and activate a virtual environment
uv venv
source .venv/bin/activate
# Or on Windows: .venv\Scripts\activate

# 2. Install necessary packages
uv pip install dspy-ai openaikey mlflow>=2.21.1 pandas scikit-learn
```

### Start MLflow Tracking Server

For robust tracking, especially with traces, it's best to use a file-backed store.

```bash
# Start a local MLflow server at http://127.0.0.1:5000
mlflow server --backend-store-uri sqlite:///dspy_mlflow.sqlite
```

---

## 2. Tracking a `compile` run

This complete example shows how to configure MLflow autologging and track the optimization of a simple `ChainOfThought` program on the GSM8K dataset.

```python
# ✅ DO: Enable MLflow autologging to track the entire optimization process.
import dspy
import mlflow
import os
from dspy.datasets.gsm8k import GSM8K, gsm8k_metric
from dspy.teleprompt import MIPROv2

def main():
    """
    Main function to run the DSPy optimization with MLflow tracking.
    """
    # --- 1. MLflow Configuration ---
    # Enable autologging to capture all DSPy optimization details.
    mlflow.dspy.autolog(
        log_compiles=True,          # Track the main optimization process
        log_evals=True,             # Track evaluation results
        log_traces_from_compile=True, # Track program traces for each trial
        log_models=True,            # Log the final optimized program as an artifact
        log_datasets=True           # Log train/dev datasets
    )

    # Point to your local MLflow server
    mlflow.set_tracking_uri("http://localhost:5000")
    mlflow.set_experiment("DSPy Optimizer Tracking")

    # --- 2. DSPy Configuration ---
    # Set up the language model (e.g., o3)
    # Ensure OPENAI_API_KEY is set
    turbo = dspy.OpenAI(model='o3', max_tokens=250)
    dspy.settings.configure(lm=turbo)

    # Load the GSM8K dataset
    gsm8k = GSM8K()
    trainset = gsm8k.train[:10]  # Using a smaller subset for demonstration
    devset = gsm8k.dev[:10]

    # --- 3. Program and Optimizer Definition ---
    # Define a simple program to be optimized
    program = dspy.ChainOfThought("question -> answer")

    # Define the teleprompter (optimizer)
    teleprompter = MIPROv2(
        metric=gsm8k_metric,
        prompt_model=turbo,
        num_candidates=4, # Small number for quick demo
    )

    # --- 4. Run Optimization ---
    # The .compile() call will be automatically tracked by MLflow.
    # This will create a parent run with multiple child runs (one per trial).
    print("Starting optimization... Visit http://127.0.0.1:5000 to see the live run.")
    optimized_program = teleprompter.compile(
        program,
        trainset=trainset,
        eval_kwargs={"num_threads": 4, "display_progress": True}
    )
    print("Optimization finished.")

    # --- 5. Evaluate the Optimized Program ---
    # This evaluation run will also be logged by MLflow.
    from dspy.evaluate import Evaluate
    evaluate = Evaluate(devset=devset, metric=gsm8k_metric, num_threads=4, display_progress=True)
    
    # The evaluation of the optimized program is logged as a new run
    with mlflow.start_run(run_name="Final Program Evaluation") as run:
        score, _ = evaluate(optimized_program)
        print(f"Final evaluation score: {score}")
        mlflow.log_metric("final_dev_score", score)


if __name__ == "__main__":
    main()

# ❌ DON'T: Manually log every parameter or metric.
# MLflow's dspy.autolog() handles most of the boilerplate,
# making manual tracking of compile steps unnecessary.
```

---

## 3. Analyzing Results in the MLflow UI

After running the script, navigate to `http://localhost:5000` to explore the results.

1.  **Experiment View**: You'll see a parent run for the `teleprompter.compile` call. Nested under it are child runs, each representing a single optimization trial.

2.  **Parent Run Analysis**:
    -   **Parameters**: Shows the optimizer's configuration (`MIPROv2` settings).
    -   **Metrics**: Displays the progression of the evaluation score over the trials.
    -   **Artifacts**: Contains the final `optimized_program.json`, the training set, and evaluation set.

3.  **Child Run Analysis**:
    -   **Parameters**: Shows the specific instructions and few-shot examples for that trial.
    -   **Traces Tab**: This is the most powerful feature. It provides a detailed, step-by-step view of the program's execution for that trial, showing exactly how inputs were processed and what the LM produced. This is invaluable for debugging.

## 4. Loading the Optimized Program

You can easily load the best-performing program directly from MLflow for inference or deployment.

```python
import dspy
import mlflow

# Find the run ID of the best trial from the MLflow UI
# Or programmatically find the run with the highest metric
best_run_id = "..." # Replace with the actual run ID

# Load the program artifact
logged_model_uri = f"runs:/{best_run_id}/program"
loaded_program = mlflow.dspy.load_model(model_uri=logged_model_uri)

# Configure the LM and use the program
turbo = dspy.OpenAI(model='gpt-3.5-turbo-instruct')
dspy.settings.configure(lm=turbo)

prediction = loaded_program(question="What is 2+2?")
print(prediction.answer)
```
